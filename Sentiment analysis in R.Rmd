---
title: "Sentiment Analysis"
author: "Ekaterina P"
date: "08 02 2021"
output: github_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About

The aim of this project is to build a sentiment analysis model which will allow us to categorize words based on their sentiments, that is whether they are positive, negative and also the magnitude of it.

## Before we start
We will use the dataset of ‘sentiments’ from the tidytext package that comprises of sentiment lexicons. We will make use of the bing lexicons (classifies the sentiment into a binary category of negative or positive) to extract the sentiments out of our data.
```{r 1, echo=TRUE, warning=FALSE}
library(tidytext)
get_sentiments("bing")
```
## Sentiment Analysis
Let's import our libraries ‘janeaustenr’, ‘stringr’. The janeaustenr package will provide us with the textual data in the form of books authored by the novelist Jane Austen.
```{r 2, echo=FALSE, warning=FALSE}
library(dplyr)
library(stringr)
library(janeaustenr)

tidy_data <- austen_books() %>%
 group_by(book) %>%
 mutate(linenumber = row_number(),
   chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", 
                          ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
```
Now each row contains a single word. We will now make use of the “bing” lexicon to and implement filter() over the words that correspond to joy. We will use the book Sense and Sensibility and derive its words to implement out sentiment analysis model.

```{r 3, echo=TRUE, warning=FALSE}
positive_senti <- get_sentiments("bing") %>%
 filter(sentiment == "positive")

tidy_data %>%
 filter(book == "Emma") %>%
 semi_join(positive_senti) %>%
 count(word, sort = TRUE)
```

From our above result we observe many positive words like “good”, “amuse”, “outstanding” etc. In the next step we will use spread() function to segregate our data into separate columns of positive and negative sentiments. 

```{r 4, echo=TRUE, warning=FALSE}
library(tidyr)
bing <- get_sentiments("bing")
Emma_sentiment <- tidy_data %>%
 inner_join(bing) %>%
 count(book = "Emma" , index = linenumber %/% 80, sentiment) %>%
 spread(sentiment, n, fill = 0) %>%
 mutate(sentiment = positive - negative)
```

Let's visualize the words present in the book “Emma” based on their corresponding positive and negative scores.

```{r 5, echo=TRUE, warning=FALSE}
library(ggplot2)

ggplot(Emma_sentiment, aes(index, sentiment, fill = book)) +
 geom_bar(stat = "identity", show.legend = TRUE) +
 facet_wrap(~book, ncol = 2, scales = "free_x")
```

Count the most common positive and negative words that are present in the novel.

```{r 6, echo=TRUE, warning=FALSE}
counting_words <- tidy_data %>%
 inner_join(bing) %>%
 count(word, sentiment, sort = TRUE)
head(counting_words)
```

Now we will plot the scores along the axis that is labeled with both positive as well as negative words.

```{r 7, echo=TRUE, warning=FALSE}
counting_words %>%
 filter(n > 150) %>%
 mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
 mutate(word = reorder(word, n)) %>%
 ggplot(aes(word, n, fill = sentiment))+
 geom_col() +
 coord_flip() +
 labs(y = "Sentiment Score")
```

And finally we create a wordcloud that delineates the most recurring positive and negative words.

```{r 8, echo=TRUE, warning=FALSE}
library(reshape2)
library(wordcloud)
tidy_data %>%
 inner_join(bing) %>%
 count(word, sentiment, sort = TRUE) %>%
 acast(word ~ sentiment, value.var = "n", fill = 0) %>%
 comparison.cloud(colors = c("red", "dark green"),
          max.words = 100)
```

This word cloud will enable us to efficiently visualize the negative as well as positive groups of data. Therefore, we are now able to see the different groups of data based on their corresponding sentiments.
